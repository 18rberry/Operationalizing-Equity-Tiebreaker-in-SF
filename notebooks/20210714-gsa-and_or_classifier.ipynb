{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propositional Classifiers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I try to design classifiers that act on the set of all blocks and output a tiebreaker binary label having access only to the features given by Henry in the focal students dataset. Those features are:\n",
    "\n",
    "1. Total number of students per block (used for normalization purposes)\n",
    "2. Number of FRL students per block\n",
    "3. Number of AALPI students per block\n",
    "4. Number of FRL and AALPI students per block (i.e. intersection of those)\n",
    "5. Number of FRL or AALPI students per block (i.e. union)\n",
    "\n",
    "The column names available are:\n",
    "\n",
    "1. n\n",
    "2. nFRL and pctFRL\n",
    "3. nAALPI and pctAALPI\n",
    "4. nBoth and pctBoth\n",
    "5. nFocal and pctFocal\n",
    "\n",
    "The classifiers will evaluate a logical proposition with those features. For example, an \"AND\" classifier can be of the form:\n",
    "\n",
    "$$ \\text{AALPI} \\geq 0.5 \\quad \\text{and} \\quad \\text{FRL} \\geq 0.7 $$\n",
    "\n",
    "This classifier will give an equity tiebreaker to a block if and only if that block has over 50% of its students in the AALPI racial group and over 70% of its students receiving FRL.\n",
    "\n",
    "Currently we do not have a systematic way to think of these types of propositions. But we can evaluate their performance based on false positive and false negative rates. In the case of two parameters (i.e. two numeric comparisons), it is possible to visualize the precision-recall curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Class Syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the propositional classifier classes from the modelling library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.d04_modeling import propositional_classifier as pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMK: The first classifier will take some extra seconds to be initialized in order for the data to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = pc.andClassifier([], user=\"gabriel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In its most general form, the propositional classifier class takes as an input a list of features that we will be using for evaluation, a list of logical operators (\"and\" or \"or\"), and a list of comparisors ($\\geq$, $\\leq$, =). By default, this comparisor lists is a sequence of $\\geq$ since that is the most likely case. The lists must be in the order of the statement we want to construct, and notice that there will always be one less operator than features. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1 = pc.PropositionalClassifier([\"pctAALPI\", \"pctFRL\", \"nBoth\"], [\"and\", \"or\"], user=\"gabriel\")\n",
    "pc1.statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the parameters are not required upon initialization. Rather, the statement is constructed so we can input parameters when doing the predictions. This way we can vary parameters and build precision-recall cruves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple and/or classifiers have their own child class, in which we only need to pass the features (and comparisors if not default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc2 = pc.andClassifier([\"pctAALPI\", \"pctFRL\"], user=\"gabriel\")\n",
    "pc2.statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc3 = pc.orClassifier([\"pctAALPI\", \"pctFRL\"], user=\"gabriel\")\n",
    "pc3.statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some logical statements need parentheses. Some do not, but we would rather read them with parentheses as that is easier (for example, the first example pc1 is hard to interpret without parenthesis---computer evaluates it in order). Simply pass a tuple of features as an element. Note that operands must still be of the correct length!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc4 = pc.PropositionalClassifier([\"pctAALPI\", (\"pctFRL\", \"pctBoth\"), \"nBoth\"], [\"or\", \"and\", \"or\"], user=\"gabriel\")\n",
    "pc4.statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have initialized our statement we can use the get_solution_set method with the appropriate parameters to do a round of prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = [0.5, 0.8, 6] #parameters must match the features passed, in the order. Note the scale.\n",
    "pred1 = pc1.get_solution_set(params1)\n",
    "pred1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This index object tells us which blocks receive the tiebreaker. We can visualize the result in the San Francisco map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pc1.plot_map(params1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix of this classifier can be retrieved using the get_confusion_matrix method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1 = pc1.get_confusion_matrix(params1)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using that we can retrive any rate for evaluating purposes. We can get the FPR and FNR for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"False positive rate is {0:.2f} %\".format(100*pc1.fpr(params1)))\n",
    "print(\"False negative rate is {0:.2f} %\".format(100*pc1.fnr(params1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret the above map: we wanted the FRL percentage to be very high (above 80%) and the AALPI percentage to be at least half; OR if there were at least 10 students in a block in the intersection count, the block would be given a tiebreaker regardless of its relative composition. We can see in the map that due to the AALPI criterion having to be satisfied most blocks that received a tiebreaker are in the SouthEast (where racial minorities are more concentrated). This criterion is very restrictive: the false negative rate is super high, meaning that we \"missed\" a lot of focal students. However, very few non-focal students received an advantage (less that 15%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the parameter space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally we would like to explore several points for the trade-off between FP and FN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one-dimensional parameter spaces (i.e. only one feature is pased to the classifier, so that we have only one parameter) this can be done via analysis of the ROC curve (similar to precision-recall):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc5 = pc.PropositionalClassifier([\"pctBoth\"], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc5.statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_arr = [[x] for x in np.linspace(0, 1, num=100)]\n",
    "ROC5_df = pc5.get_roc(params_arr)\n",
    "ROC5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc5.plot_roc(params_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In two-dimensional parameter spaces (i.e. only two features are pased to the classifier, so that we have only two parameters) this can be done via analysis of two matrices of false positives and false negatives. This would be equivalent to a ROC surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc2.statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_arr2 = [x/10 for x in range(11)]\n",
    "pc2.plot_heatmap(params_arr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative is to fix all but one parameters of the propositions so that we can build a ROC curve. Using:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\left(\\text{AALPI } \\geq 50\\%  \\quad \\text{and} \\quad \\text{FRL } \\geq 60\\%\\right)\\quad\\text{or}\\quad \\text{BOTH } (\\%)\\geq \\gamma$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc6 = pc.PropositionalClassifier([(\"pctAALPI\", \"pctFRL\"), \"pctBoth\"], [\"and\", \"or\"])\n",
    "pc6.statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_arr6 = [[0.5, 0.6, x] for x in np.linspace(0, 1, num=100)]\n",
    "pc6.plot_roc(params_arr6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because we are looking at a subset of the parameter space, we cannot acheive all possible values of FPR/TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
