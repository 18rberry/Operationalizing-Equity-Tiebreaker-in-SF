{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.d01_data.block_data_api import BlockDataApi\n",
    "from src.d01_data.student_data_api import StudentDataApi, _block_features, _census_block_column, \\\n",
    "_diversity_index_features\n",
    "\n",
    "geoid_name = 'geoid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data\n",
    "Load data indexed by the `census_block`/`Block`/`Geoid10`\n",
    "1. Load FRL data\n",
    "2. Load Block demographics\n",
    "3. Load Block demographics computed from student data (fill in before computing the demographics from the block data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLR data\n",
    "This data should be indexed by the column `Geoid10` as type `int64`.\n",
    "\n",
    "We convert the `group` column into a more coherent index. In the original data there group ids is a integer from `1` to `353` for the blocks that are grouped together and the GEOID for the blocks that stand alone. For some reason the blocks that are grouped together only have `327` (not `353`) unique group indexes. Because of this, the max value of the new index is `3311` instead of `3285` (the actual length of the vector of unique group indexes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_data_api = BlockDataApi()\n",
    "\n",
    "frl_df = block_data_api.get_data(frl=True, user=\"juan\").set_index('Geoid10')\n",
    "frl_df.index.name = geoid_name\n",
    "frl_df.columns = ['group', 'n', 'nFRL', 'nAALPI', 'nBoth']\n",
    "frl_df['pctFRL'] = frl_df['nFRL'] / frl_df['n']\n",
    "frl_df['pctAALPI'] = frl_df['nAALPI'] / frl_df['n']\n",
    "frl_df['pctBoth'] = frl_df['nBoth'] / frl_df['n']\n",
    "\n",
    "# TODO: What happens if 'pctBoth' = 'nBoth' / ('nFRL' + 'nAALPI' - 'nBoth')\n",
    "\n",
    "# we want to find the blocks that share a group index\n",
    "mask = frl_df['group'] < 1000\n",
    "last_group_index = frl_df.loc[mask, 'group'].max()\n",
    "# then we generate a new set of group indexes for the standalone blocks that is more coherent \n",
    "# with the indexes of the grouped blocks\n",
    "num_of_new_indexes = np.sum(~mask)\n",
    "new_group_index = np.arange(num_of_new_indexes) + 1 + last_group_index\n",
    "\n",
    "frl_df.at[~mask, 'group'] = new_group_index\n",
    "frl_df['group'] = frl_df['group'].astype('int64')\n",
    "print(frl_df.shape)\n",
    "frl_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Demographics\n",
    "\n",
    "This data should be indexed by the column `Block` as type `int64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = block_data_api.get_data().set_index('Block')['BlockGroup'].dropna()\n",
    "demo_df.index.name = geoid_name\n",
    "print(demo_df.shape)\n",
    "print(demo_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Demographics\n",
    "\n",
    "This data should be indexed by the column `census_block` as type `int64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods_list = [\"1415\", \"1516\", \"1617\", \"1718\", \"1819\", \"1920\"]\n",
    "student_data_api = StudentDataApi()\n",
    "\n",
    "df_students = student_data_api.get_data(periods_list)\n",
    "mask = df_students[_census_block_column] == 'NaN'\n",
    "df_students.drop(df_students.index[mask], inplace=True)\n",
    "df_students[geoid_name]=df_students['census_block'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_value(x):\n",
    "    return x.iloc[0]\n",
    "\n",
    "stud_df = df_students.groupby(geoid_name)[_diversity_index_features].agg(get_group_value)\n",
    "print(stud_df.shape)\n",
    "stud_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check indexes\n",
    "\n",
    "df = pd.concat([demo_df.to_frame(), stud_df.reindex(demo_df.index), frl_df.reindex(demo_df.index)],\n",
    "               axis=1,\n",
    "               ignore_index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creat map plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata_path = '/share/data/school_choice/dssg/census2010/'\n",
    "file_name = 'geo_export_e77bce0b-6556-4358-b36b-36cfcf826a3c'\n",
    "data_types = ['.shp', '.dbf', '.prj', '.shx']\n",
    "\n",
    "sfusd_map = gpd.read_file(geodata_path + file_name + data_types[0])\n",
    "sfusd_map[geoid_name] = sfusd_map['geoid10'].astype('int64')\n",
    "sfusd_map.set_index(geoid_name, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_cols = ['group', 'pctFRL', 'pctAALPI', 'pctBoth']\n",
    "sfusd_map_df = pd.concat([sfusd_map.reindex(df.index), df[pct_cols]], axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_column(df_map, column, cmap=\"viridis\"):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(30,30))\n",
    "    \n",
    "    if \"Count\" in column:\n",
    "        cmap = \"PRGn\"\n",
    "    elif \"%\" in column:\n",
    "        cmap = \"YlOrRd\"\n",
    "    \n",
    "    df_map.plot(column=column, ax=ax, cmap=cmap, \n",
    "                         legend=True, legend_kwds={'orientation': \"horizontal\"},\n",
    "                         missing_kwds={'color': 'lightgrey'})\n",
    "    ax.set_title(column, fontsize=50)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_column(sfusd_map_df, 'pctFRL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve Knapsack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to solve Knapsack problem for the block groups given by the `group` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['n', 'nFRL', 'group']].groupby('group').agg(get_group_value)\n",
    "target_group = 'nFRL'\n",
    "data['nOther'] = data['n'] - data[target_group]\n",
    "data.dropna(inplace=True)\n",
    "data = data.round().astype('int64')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.d04_modeling.knapsack_approx import KnapsackApprox\n",
    "\n",
    "if False:\n",
    "    solver = KnapsackApprox(eps=.5, data=data.copy(),\n",
    "                            value_col=target_group,\n",
    "                            weight_col='nOther',\n",
    "                            scale=False)\n",
    "\n",
    "    solver.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_students = data['n'].sum()\n",
    "fp_rate = 0.1\n",
    "w_max = fp_rate * total_students\n",
    "print(total_students, w_max)\n",
    "if False:\n",
    "    v_opt, solution_set = solver.get_solution(w_max=w_max)\n",
    "    solution_set = pd.Index(solution_set, name=data.index.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    solution_set.to_series().to_pickle('solution_set.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_set = pd.read_pickle('solution_set.pkl')\n",
    "solution_set = pd.Index(solution_set.values, name=geoid_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Lets see what our assignment looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['focal'] = 0\n",
    "data.loc[solution_set, 'focal'] = 1\n",
    "data.groupby('focal').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the number of `nOther` labeled as `focal = 1` is roughly 10 percent of the total students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(x, solution_set):\n",
    "    if np.isfinite(x):\n",
    "        return 1. if x in solution_set else 0.\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "sfusd_map_df['focal'] = sfusd_map_df['group'].apply(lambda x: get_label(x, solution_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_column(sfusd_map_df, 'focal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Logistic Regression\n",
    "\n",
    "We now use the labeled data to train a logistic regression over the aggregated block data\n",
    "\n",
    "## Model\n",
    "\n",
    "We can use the contribution of each block group to their label as weights for the training process. Let each block $b$ be of type $y=k$, with $k\\in \\{0,1\\}$, have $v_b$ focal students and $u_b$ non-focal students. Then we can define the weight of each block $w_b$ in the training process as\n",
    "\n",
    "$$w_b = \\frac{\\mathbb{I}(y_b=1)v_b + \\mathbb{I}(y_b=0)u_b}{\\sum_b\\mathbb{I}(y_b=1)v_b + \\mathbb{I}(y_b=0)u_b}$$\n",
    "\n",
    "First we should inspect what our new labeled data set looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled = df.copy()\n",
    "df_labeled['focal'] = df_labeled['group'].apply(lambda x: get_label(x, solution_set))\n",
    "df_labeled.dropna(inplace=True)\n",
    "df_labeled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also see what each block group looks like. Do they have the same demographic characteristics? Maybe this is an analysis that should have been done previously? Should we have grouped the blocks under the column `'BlockGroup'` instead of an psudo-arbitrary assigment (what Joseph did)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_labeled['group'] == 50\n",
    "df_labeled.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that blocks in the same `group` have different demographics. We are going to group and average the demographics. __Note__: _Since the counts are constant group counts, taking the average of these columns should yield the group counts. The same goes for the focal labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_glm = df_labeled.groupby('group').mean()\n",
    "data_glm['focal'] = data_glm['focal'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_glm.loc[50].to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_glm['nOther'] = data_glm['n'] - data_glm[target_group]\n",
    "summary = data_glm[['focal', 'n', 'nOther', target_group]].round().astype('int64')\n",
    "summary = summary.groupby('focal').sum()\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary / summary['n'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_covariates = df_labeled[_diversity_index_features].astype('float64')\n",
    "glm_covariates['const'] = 1.\n",
    "glm_covariates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_response = df_labeled['focal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_binom = sm.GLM(glm_response, glm_covariates, family=sm.families.Binomial())\n",
    "res = glm_binom.fit()\n",
    "print(res.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dssg-env",
   "language": "python",
   "name": "dssg-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
